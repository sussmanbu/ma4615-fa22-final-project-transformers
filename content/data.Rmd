---
title: Data
description:
toc: true
featuredVideo:
featuredImage: images/data-import-cheatsheet-thumbs.png
draft: false
---

## Rubric: On this page

* Where/how to find data (link to original data source): 
 https://osf.io/td7mk: More details regarding the dataset can be found here: https://osf.io/kthnf/
 
* Why was the data collected/curated? Who put it together?:
This dataset is by the Guttmacher Institute, a policy institution focused on “advancing sexual and reproductive health and rights (SRHR) worldwide.” [1] It displays data related to pregnancies, births, abortions and miscarriages for each state in the United States from 1988 to 2017. 

* Describe the different data files used and what each variable means. 
  * If you have many variables then only describe the most relevant ones and summarize the rest.
  
There are 912 rows and 50 columns in this dataset. For each row (observation), the state, year, and statistics for the various age groups are given. For each age group, there is statistics for pregnancy rate, abortion rate, birth rate, abortion ratio (Number of abortions per 1000 births), number of pregnancies, miscarriages, abortions, births and the population of women. The age groups of the women are as follows: less than 15, 15 - 17, 18 - 19, 15  - 19, less than 20, 20 - 24, 25 - 29, 30 - 34, 35 - 29 and 40 plus. The data was originally collected because the Guttmacher Institute believed that “ Documenting pregnancy, birth and abortion rates over time and by age-group helps illustrate broadly how people’s reproductive lives have changed over the past four decades.” [2] The counts of births by age were obtained from the National Center for Health Statistics, which “provides annual counts of births in the United States, as compiled in the National Vital Statistics System from data derived from birth certificates.” [2] The counts of abortions by state were from the Guttmacher Institute’s “periodic national Abortion Provider Census.” [2],  Centers for Disease Control and Prevention Abortion Surveillance Reports and data from state health departments [3]. The population of women was obtained from the Census Bureau [3].

[1] “About”. guttmacher.org. https://www.guttmacher.org/about (accessed Oct 12, 2022)
[2] I. Maddow-Zimet and K. Kost. “Pregnancies, Births and Abortions in the United States, 1973–2017: National and State Trends by Age”. guttmacher.org. https://www.guttmacher.org/report/pregnancies-births-abortions-in-united-states-1973-2017 (accessed Oct. 12, 2022)
[3] I. Maddow-Zimet and K. Kost. “Pregnancies, Births and Abortions in the
United States, 1973–2017: National and State Trends by Age Methodology Appendix”. guttmacher.org. https://www.guttmacher.org/sites/default/files/report_downloads/pregnancies-births-abortions-us-1973-2017-method-appendix.pdf (accessed Oct. 12, 2022)

* Describe any cleaning you had to do for your data.
  * You *must* include a link to your `load_and_clean_data.R` file.
  * Also, describe any additional R packages you used outside of those covered in class.
  
  * Describe and show code for how you combined multiple data files and any cleaning that was necessary for that.
  
  * Some repetition of what you do in your `load_and_clean_data.R` file is fine and encouraged if it helps explain what you did.
  
* Organization, clarity, cleanliness of the page
  * Make sure to remove excessive warnings, use clean easy-to-read code (without side scrolling), organize with sections, use bullets and other organization tools, etc.



----------------------------------------------
This comes from the file `content/data.Rmd`.

Your first steps in this project will be to find data to work on.

I recommend trying to find data that interests you and that you are knowledgeable about. A bad example would be if you have no interest in video games but your data set is about video games. I also recommend finding data that is related to current events, social justice, and other areas that have an impact.

You are __not__ allowed to work on COVID data.

Initially, you will study _one dataset_ but later you will need to combine that data with another dataset. For this reason, I recommend finding data that has some date and/or location components. These types of data are conducive to interesting visualizations and analysis and you can also combine this data with other data that also has a date or location variable.
Data from the census, weather data, economic data, are all relatively easy to combine with other data with time/location components.


## Where to keep data?


Below 50mb: In `dataset` folder

Above 50mb: In `dataset_ignore` folder. This folder will be ignored by `git` so you'll have to manually sync these files across your team.

### Sharing your data


For small datasets (<50mb), you can use the `dataset` folder that is tracked by github. Add the files just like you would any other file.

**Do not** use a folder named `data`.
This folder is reserved by `hugo`.
If you create a folder named `data` this will cause problems.

For larger datasets, you'll need to create a new folder in the project root directory named `dataset-ignore`. This will be ignored by git (based off the `.gitignore` file in the project root directory) which will help you avoid issues with Github's size limits. Your team will have to manually make sure the data files in `dataset-ignore` are synced across team members.

Your [load_and_clean_data.R](/load_and_clean_data.R) file is how you will load and clean your data. Here is a an example of a very simple one.

```{r}
source(
  here::here("static", "load_and_clean_data.R"),
  echo = TRUE # Use echo=FALSE or omit it to avoid code output  
)
```

Note how I use the `here::here` function from the [`here` package](https://here.r-lib.org/articles/here.html) to avoid path problems.
This function is used to specify directories within the project's root directory.
You should never use absolute paths (eg. `/Users/danielsussman/path/to/project/` or `C:\\MA415\\Final_Project\\`) and using `here` ensures that it doesn't matter what the current working directory is as long as you have this RStudio Project open.

----



## Files in static

### `load_and_clean_data.R`

The idea behind this file is that someone coming to your website could largely replicate your analyses after running this script on the original data sets to clean them.
This file might create a derivative data set that you then use for your subsequent analysis.
Note that you don't need to run this script from every post/page.
Instead, you can load in the results of this script, which could be plain text files or `.RData` files. In your data page you'll describe how these results were created. If you have a very large data set, you might save smaller data sets that you can use for exploration purposes.
To link to this file, you can use `[cleaning script](/load_and_clean_data.R)`. 


When you are loading in data, I recommend using the `here::here` function to specify the file path. This function is used to specify a path relative to your project's root directory. Hence, you can read a file using eg, `read_csv(here::here("dataset/data_file.csv"))`.


### Shiny Interactive

If you are using a shiny interactive, you'll need to keep that in a separate folder (i.e. not in `static` or `content`). For the shiny interactive you'll need to publish the app on `shinyapps.io` where the app can be run. When you publish, make sure to include any data sets you are loading in among the files you publish since those datasets will need to be loaded by your app. 





----

